{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O8gU7AYPXMmA"
   },
   "source": [
    "## About iPython Notebooks ##\n",
    "\n",
    "iPython Notebooks are interactive coding environments embedded in a webpage. You will be using iPython notebooks in this class. Make sure you fill in any place that says `# BEGIN CODE HERE #END CODE HERE`. After writing your code, you can run the cell by either pressing \"SHIFT\"+\"ENTER\" or by clicking on \"Run\" (denoted by a play symbol). Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All). \n",
    "\n",
    " **What you need to remember:**\n",
    "\n",
    "- Run your cells using SHIFT+ENTER (or \"Run cell\")\n",
    "- Write code in the designated areas using Python 3 only\n",
    "- Do not modify the code outside of the designated areas\n",
    "- In some cases you will also need to explain the results. There will also be designated areas for that. \n",
    "\n",
    "Fill in your **NAME** and **AEM** below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "lO-jJrtNXMmH",
    "ExecuteTime": {
     "start_time": "2023-06-26T10:49:02.032112Z",
     "end_time": "2023-06-26T10:49:02.034341Z"
    }
   },
   "outputs": [],
   "source": [
    "NAME = \"Christina Koutsou\"\n",
    "AEM = \"9994 (ECE)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sh0EE7BJXMmJ"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v_VpnGyWXMmK"
   },
   "source": [
    "# Assignment 3 - Ensemble Methods #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2dQ9XoGQXMmK"
   },
   "source": [
    "Welcome to your third assignment. This exercise will test your understanding on Ensemble Methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "JvHYIhS-XMmL",
    "ExecuteTime": {
     "start_time": "2023-06-26T10:50:59.712602Z",
     "end_time": "2023-06-26T10:50:59.715556Z"
    }
   },
   "outputs": [],
   "source": [
    "# Always run this cell\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# USE THE FOLLOWING RANDOM STATE FOR YOUR CODE\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "joKwpih2XMmM"
   },
   "source": [
    "## Download the Dataset ##\n",
    "Download the dataset using the following cell or from this [link](https://github.com/sakrifor/public/tree/master/machine_learning_course/EnsembleDataset) and put the files in the same folder as the .ipynb file. \n",
    "In this assignment you are going to work with a dataset originated from the [ImageCLEFmed: The Medical Task 2016](https://www.imageclef.org/2016/medical) and the **Compound figure detection** subtask. The goal of this subtask is to identify whether a figure is a compound figure (one image consists of more than one figure) or not. The train dataset consits of 4197 examples/figures and each figure has 4096 features which were extracted using a deep neural network. The *CLASS* column represents the class of each example where 1 is a compoung figure and 0 is not. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NJdwPr0bXMmM",
    "outputId": "dc14a3cc-7133-4b2c-a425-4453ee801ee8",
    "ExecuteTime": {
     "start_time": "2023-06-20T21:37:50.847248Z",
     "end_time": "2023-06-20T21:38:15.938450Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "('test_set_noclass.csv', <http.client.HTTPMessage at 0x7f68b9bb28c0>)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "url_train = 'https://github.com/sakrifor/public/raw/master/machine_learning_course/EnsembleDataset/train_set.csv'\n",
    "filename_train = 'train_set.csv'\n",
    "urllib.request.urlretrieve(url_train, filename_train)\n",
    "url_test = 'https://github.com/sakrifor/public/raw/master/machine_learning_course/EnsembleDataset/test_set_noclass.csv'\n",
    "filename_test = 'test_set_noclass.csv'\n",
    "urllib.request.urlretrieve(url_test, filename_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "t0OVtYr7XMmN",
    "ExecuteTime": {
     "start_time": "2023-06-26T11:41:47.675699Z",
     "end_time": "2023-06-26T11:41:50.194949Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell to load the data\n",
    "train_set = pd.read_csv(\"train_set.csv\").sample(frac=1).reset_index(drop=True)\n",
    "train_set.head()\n",
    "X = train_set.drop(columns=['CLASS'])\n",
    "y = train_set['CLASS'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4XK751YSecqQ",
    "ExecuteTime": {
     "start_time": "2023-06-20T21:39:34.469142Z",
     "end_time": "2023-06-20T21:39:40.789170Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -U imbalanced-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tQH40Vb5fvx2"
   },
   "source": [
    "The following code will reduce the number of instances, dealing with the small imbalance of the dataset, as well as reducing the size of the dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DIgD6Nmkeaxv",
    "outputId": "38039fc6-786f-4a7e-cccb-b5843c1fef61",
    "ExecuteTime": {
     "start_time": "2023-06-26T11:41:52.858103Z",
     "end_time": "2023-06-26T11:41:57.173146Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({0: 1687, 1: 1687})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from imblearn.under_sampling import NeighbourhoodCleaningRule, RandomUnderSampler\n",
    "\n",
    "ncr = NeighbourhoodCleaningRule()\n",
    "X_res, y_res = ncr.fit_resample(X, y)\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_res, y_res = rus.fit_resample(X_res, y_res)\n",
    "print('Resampled dataset shape %s' % Counter(y_res))\n",
    "X = X_res\n",
    "y = y_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZxOGHSmqXMmO"
   },
   "source": [
    "## 1.0 Testing different ensemble methods ##\n",
    "In this part of the assignment you are asked to create and test different ensemble methods using the train_set.csv dataset. You should use **5-fold cross validation** for your tests and report the average f-measure weighted and balanced accuracy of your models. You can use [cross_validate](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate) and select both metrics to be measured during the evaluation. \n",
    "\n",
    "### !!! Use n_jobs=-1 where is posibble to use all the cores of a machine for running your tests ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ww_u4OlrXMmO"
   },
   "source": [
    "### 1.1 Voting ###\n",
    "Create a voting classifier which uses two **simple** estimators/classifiers. Test both soft and hard voting and report the results. Consider as simple estimators the following:\n",
    "\n",
    "\n",
    "*   Decision Trees\n",
    "*   Linear Models\n",
    "*   KNN Models  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "9xKWBVWVz3yV",
    "ExecuteTime": {
     "start_time": "2023-06-26T11:42:00.859388Z",
     "end_time": "2023-06-26T11:42:46.398987Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier:\n",
      "VotingClassifier(estimators=[('cls1_soft',\n",
      "                              DecisionTreeClassifier(max_depth=3,\n",
      "                                                     max_leaf_nodes=100,\n",
      "                                                     random_state=42)),\n",
      "                             ('cls2_soft',\n",
      "                              LogisticRegression(max_iter=800, n_jobs=-1,\n",
      "                                                 random_state=42))],\n",
      "                 n_jobs=-1, voting='soft')\n",
      "F1 Weighted-Score: 0.8897 & Balanced Accuracy: 0.8898\n",
      "Classifier:\n",
      "VotingClassifier(estimators=[('cls1_hard',\n",
      "                              DecisionTreeClassifier(max_depth=3,\n",
      "                                                     max_leaf_nodes=100,\n",
      "                                                     random_state=42)),\n",
      "                             ('cls2_hard',\n",
      "                              LogisticRegression(max_iter=800, n_jobs=-1,\n",
      "                                                 random_state=42))],\n",
      "                 n_jobs=-1)\n",
      "F1 Weighted-Score: 0.8431 & Balanced Accuracy: 0.8441\n"
     ]
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# USE RANDOM STATE!\n",
    "cls1 = DecisionTreeClassifier(criterion='gini', max_depth=3, max_leaf_nodes=100, random_state=RANDOM_STATE) # Classifier #1\n",
    "cls2 = LogisticRegression(max_iter = 800, random_state=RANDOM_STATE, n_jobs=-1) # Classifier #2, penalty is 'l2' by default, increased iterations limit to have better accuracy (but it takes longer to calculate and the difference isn't significant)\n",
    "soft_vcls = VotingClassifier(estimators=[('cls1_soft',cls1),('cls2_soft',cls2)], voting='soft', n_jobs=-1)\n",
    "hard_vcls = VotingClassifier(estimators=[('cls1_hard',cls1),('cls2_hard',cls2)], voting='hard', n_jobs=-1)\n",
    "\n",
    "svlcs_scores = cross_validate(estimator=soft_vcls, X=X, y=y, scoring=['f1_weighted', 'balanced_accuracy'], n_jobs=-1) # 5-fold cross validation is used by default (cv=5)\n",
    "s_avg_fmeasure = svlcs_scores['test_f1_weighted'].mean() # The average f-measure\n",
    "s_avg_accuracy = svlcs_scores['test_balanced_accuracy'].mean() # The average accuracy\n",
    "\n",
    "hvlcs_scores = cross_validate(estimator=hard_vcls, X=X, y=y, scoring=['f1_weighted', 'balanced_accuracy'], n_jobs=-1)\n",
    "h_avg_fmeasure = hvlcs_scores['test_f1_weighted'].mean() # The average f-measure\n",
    "h_avg_accuracy = hvlcs_scores['test_balanced_accuracy'].mean() # The average accuracy\n",
    "\n",
    "### END SOLUTION\n",
    "\n",
    "print(\"Classifier:\")\n",
    "print(soft_vcls)\n",
    "print(\"F1 Weighted-Score: {} & Balanced Accuracy: {}\".format(round(s_avg_fmeasure,4), round(s_avg_accuracy,4)))\n",
    "\n",
    "print(\"Classifier:\")\n",
    "print(hard_vcls)\n",
    "print(\"F1 Weighted-Score: {} & Balanced Accuracy: {}\".format(round(h_avg_fmeasure,4), round(h_avg_accuracy,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "92ubbtE8gtHy"
   },
   "source": [
    "For both soft/hard voting classifiers the F1 weighted score should be above 0.74 and 0.79, respectively, and for balanced accuracy 0.74 and 0.80. Remember! This should be the average performance of each fold, as measured through cross-validation with 5 folds!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KPG8MdFLXMmV"
   },
   "source": [
    "### 1.2 Randomization\n",
    "\n",
    "You are asked to create three ensembles of decision trees where each one uses a different method for producing homogeneous ensembles. Compare them with a simple decision tree classifier and report your results in the dictionaries (dict) below using as key the given name of your classifier and as value the f1_weighted/balanced_accuracy score. The dictionaries should contain four different elements. Use the same cross-validation approach as before! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "PmkaP-DjXMmV",
    "ExecuteTime": {
     "start_time": "2023-06-26T11:42:55.483463Z",
     "end_time": "2023-06-26T11:45:11.194650Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(max_depth=10, max_leaf_nodes=100, n_jobs=-1,\n",
      "                       random_state=42)\n",
      "AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=10,\n",
      "                                                    max_leaf_nodes=100,\n",
      "                                                    random_state=42),\n",
      "                   random_state=42)\n",
      "BaggingClassifier(estimator=DecisionTreeClassifier(max_depth=10,\n",
      "                                                   max_leaf_nodes=100,\n",
      "                                                   random_state=42),\n",
      "                  n_jobs=-1, random_state=42)\n",
      "DecisionTreeClassifier(max_depth=10, max_leaf_nodes=100, random_state=42)\n",
      "Classifier: Ensemble with Random Forest classifier -  F1 Weighted: 0.85\n",
      "Classifier: Ensemble with Ada Boost classifier -  F1 Weighted: 0.8476\n",
      "Classifier: Ensemble with Bagging classifier -  F1 Weighted: 0.8321\n",
      "Classifier: Simple Decision -  F1 Weighted: 0.754\n",
      "Classifier: Ensemble with Random Forest classifier -  BalancedAccuracy: 0.85\n",
      "Classifier: Ensemble with Ada Boost classifier -  BalancedAccuracy: 0.8477\n",
      "Classifier: Ensemble with Bagging classifier -  BalancedAccuracy: 0.8322\n",
      "Classifier: Simple Decision -  BalancedAccuracy: 0.754\n"
     ]
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier\n",
    "\n",
    "ens1 = RandomForestClassifier(max_depth=10, max_leaf_nodes=100, random_state=RANDOM_STATE, n_jobs=-1) #same parameters with the simple decision tree classifier\n",
    "# for the comparison to be more accurate, not necessary to have such a complicated base with many parameters in order to compare them\n",
    "ens2 = AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=10, max_leaf_nodes=100, random_state=RANDOM_STATE), random_state=RANDOM_STATE)\n",
    "ens3 = BaggingClassifier(estimator=DecisionTreeClassifier(max_depth=10, max_leaf_nodes=100, random_state=RANDOM_STATE), random_state=RANDOM_STATE, n_jobs=-1)\n",
    "tree = DecisionTreeClassifier(criterion='gini', max_depth=10, max_leaf_nodes=100, random_state=RANDOM_STATE)\n",
    "\n",
    "ens1_scores = cross_validate(estimator=ens1, X=X, y=y, scoring=['f1_weighted', 'balanced_accuracy'], n_jobs=-1) # 5-fold cross validation is used by default (cv=5)\n",
    "ens2_scores = cross_validate(estimator=ens2, X=X, y=y, scoring=['f1_weighted', 'balanced_accuracy'], n_jobs=-1)\n",
    "ens3_scores = cross_validate(estimator=ens3, X=X, y=y, scoring=['f1_weighted', 'balanced_accuracy'], n_jobs=-1)\n",
    "tree_scores = cross_validate(estimator=tree, X=X, y=y, scoring=['f1_weighted', 'balanced_accuracy'], n_jobs=-1)\n",
    "\n",
    "f_measures = {'Ensemble with Random Forest classifier': ens1_scores['test_f1_weighted'].mean(),\n",
    "              'Ensemble with Ada Boost classifier': ens2_scores['test_f1_weighted'].mean(),\n",
    "              'Ensemble with Bagging classifier': ens3_scores['test_f1_weighted'].mean(),\n",
    "              'Simple Decision': tree_scores['test_f1_weighted'].mean()\n",
    "              }\n",
    "accuracies = {'Ensemble with Random Forest classifier': ens1_scores['test_balanced_accuracy'].mean(),\n",
    "              'Ensemble with Ada Boost classifier': ens2_scores['test_balanced_accuracy'].mean(),\n",
    "              'Ensemble with Bagging classifier': ens3_scores['test_balanced_accuracy'].mean(),\n",
    "              'Simple Decision': tree_scores['test_balanced_accuracy'].mean()\n",
    "              }\n",
    "# Example f_measures = {'Simple Decision':0.8551, 'Ensemble with random ...': 0.92, ...}\n",
    "\n",
    "\n",
    "### END SOLUTION\n",
    "\n",
    "print(ens1)\n",
    "print(ens2)\n",
    "print(ens3)\n",
    "print(tree)\n",
    "for name,score in f_measures.items():\n",
    "    print(\"Classifier: {} -  F1 Weighted: {}\".format(name,round(score,4)))\n",
    "for name,score in accuracies.items():\n",
    "    print(\"Classifier: {} -  BalancedAccuracy: {}\".format(name,round(score,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lkJeuV1FXMmX"
   },
   "source": [
    "### 1.3 Question\n",
    "\n",
    "Increasing the number of estimators in a bagging classifier can drastically increase the training time of a classifier. Is there any solution to this problem? Can the same solution be applied to boosting classifiers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ApNEPcWEXMmY"
   },
   "source": [
    "The most efficient way to reduce the time it takes for the calculations to be performed is to parallelize the procedures of sampling the dataset and of forming smaller decision trees, as each tree is independent of the other. However, this can not be applied to the boosting classifiers as at each iteration the sample weights change and influence the samples chosen for the next iteration. So, each estimator's training depends on the previous estimators' performance and sample weights, which makes this procedure sequential and, thus, it cannot be parallelized. Although, once the boosting process is completed and all the estimators (weak models) are trained, they can be used independently to make predictions on new instances in parallel.\n",
    "Other methods to reduce the calculation time of a bagging classifier is limiting the number of samples or the depth of each estimator tree and overall limit its accuracy to gain time. However this would probably not be optimal or save much time. In contrast, deducting the training to a subset of the original set by giving it as an input to cross_validation could yield better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XgvsCbUGXMmY"
   },
   "source": [
    "## 2.0 Creating the best classifier ##\n",
    "In the second part of this assignment, we will try to train the best classifier, as well as to evaluate it using stratified cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q6daX2mRXMmZ"
   },
   "source": [
    "### 2.1 Good Performing Ensemble\n",
    "\n",
    "In this part of the assignment you are asked to train a good performing ensemble, that is able to be used in a production environment! Describe the process you followed to achieve this result. How did you choose your classifier and your parameters and why. Report the f-measure (weighted) & balanced accuracy, using 10-fold stratified cross validation, of your final classifier. Can you achieve a balanced accuracy over 88%, while keeping the training time low? (Tip 1: You can even use a model from the previous parts, but you are advised to test additional configurations, and ensemble architectures, Tip 2: If you try a lot of models/ensembles/configurations or even grid searches, in your answer leave only the classifier you selected as the best!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "00xAQ0HfXMmZ",
    "ExecuteTime": {
     "start_time": "2023-06-26T11:54:24.506561Z",
     "end_time": "2023-06-26T11:55:25.429113Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier:\n",
      "StackingClassifier(estimators=[('KNeighbors', KNeighborsClassifier(n_jobs=-1)),\n",
      "                               ('Random Forest',\n",
      "                                RandomForestClassifier(bootstrap=False,\n",
      "                                                       max_depth=25,\n",
      "                                                       max_leaf_nodes=300,\n",
      "                                                       n_jobs=-1,\n",
      "                                                       random_state=42))],\n",
      "                   n_jobs=-1)\n",
      "F1 Weighted-Score: 0.8900151148519637 & Balanced Accuracy: 0.8900288813750352\n"
     ]
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "est1 = KNeighborsClassifier(n_jobs=-1)\n",
    "est2 = RandomForestClassifier(max_depth=25, max_leaf_nodes=300, n_jobs=-1, random_state=RANDOM_STATE, bootstrap=False) # parameters pointed out by a grid search, default values are not specified\n",
    "\n",
    "best_cls = StackingClassifier(estimators=[('KNeighbors', est1), ('Random Forest', est2)], n_jobs=-1)\n",
    "\n",
    "str_folds = StratifiedKFold(n_splits=10,shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "best_cls_scores = cross_validate(estimator=best_cls, X=X, y=y, scoring=['f1_weighted', 'balanced_accuracy'], n_jobs=-1, cv=str_folds, return_estimator=True)\n",
    "\n",
    "best_model_index = best_cls_scores['test_balanced_accuracy'].argmax()\n",
    "best_model = best_cls_scores['estimator'][best_model_index] # best model\n",
    "\n",
    "# To report the performance of the best model:\n",
    "# best_fmeasure =  best_cls_scores['test_f1_weighted'].max()\n",
    "# best_accuracy =  best_cls_scores['test_balanced_accuracy'].max() # highest accuracy\n",
    "\n",
    "best_fmeasure =  best_cls_scores['test_f1_weighted'].mean()\n",
    "best_accuracy =  best_cls_scores['test_balanced_accuracy'].mean() # highest accuracy\n",
    "\n",
    "### END SOLUTION\n",
    "\n",
    "print(\"Classifier:\")\n",
    "print(best_cls)\n",
    "print(\"F1 Weighted-Score: {} & Balanced Accuracy: {}\".format(best_fmeasure, best_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lnAp-d2DXMmf"
   },
   "source": [
    "Read part 2.2 first for better understanding. The grid search for Random Forest indicated better training accuracy for `bootstrap=True`, but the accuracy of the predictions for the testing set was higher in the case of `bootstrap=False`, so this was used instead (probably due to a slight overfitting). The values of the parameters that matched the default ones were neglected in the function call. To compare the ensembles, the `mean()` method was used for the scores. The best model is identified in this cell to give the ability to print its scores using the commented out lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vnos1uqzXMma"
   },
   "source": [
    "### 2.2 Question\n",
    " What other ensemble architectures you tried, and why you did not choose them as your final classifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o5dAfbTfXMmb"
   },
   "source": [
    "From part 1, I observed that the Random Forest classifier produces the highest accuracy and can also be parallelized which would be time efficient. However, even after a grid search on some variables regarding the estimator trees, the balanced accuracy score could not reach over 0.87. Afterwards, I tried Ada boost instead but still could not produce that high of an accuracy.\n",
    "My next thought was to use a combination of methods. Since Ada Boost and Random Forest could only improve the model up to a certain point and performed very similarly at part 1.2, their combination would probably not increase the accuracy much further (and it was confirmed through testing as well). So, another estimator should be used along with Random Forest which is preferred from Ada Boost due the fact that it enables the parallel production of its estimators. Looking into the [suggestions of scikit-learn](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html), amd trying LinearSVC, KNeighbors and SVC, the accuracy was increasing along the way, reaching an average value of 0.9 in the case of SVC. However, the time it took for the training using the SVC method was significant (around 7 minutes). LinearSVC took less time but still considerable, but KNeighbors allows parallelization and produced better accuracy than LinearSVC, though lower than SVC. Since we want to achieve an accuracy of over 88% and keep the training time as low as possible, the trade-off between KNeighbors and SVC tended to favor the first one as the optimal option. Other estimators that were considered and tried out are SDG and K-Mean (this one is usually used for clustering but was configured for classification in this case).\n",
    "\n",
    "Parameter grid search for Random Forest:\n",
    "```\n",
    "param_grid = {\n",
    "    \"min_samples_leaf\": [1, 10, 20, 50],\n",
    "    \"max_leaf_nodes\": [10, 50, 100, 150, 300],\n",
    "    \"bootstrap\": [True, False],\n",
    "    \"max_features\": ['sqrt', 'log']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(est2, param_grid, cv=10, n_jobs=-1) # replace est2 with a Random Forest classifier, use 10-fold cross validation\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"Best params:\")\n",
    "print(grid_search.best_params_)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dI1yb95A8r3k"
   },
   "source": [
    "### 2.3 Setup the Final Classifier\n",
    "Finally, in this last cell, set the cls variable to either the best model as occurred by the stratified cross_validation, or choose to retrain your classifier in the whole dataset (X, y). There is no correct answer, but try to explain your choice. Then, save your model using pickle and upload it with your submission to e-learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "GYNkmiUOXMmh",
    "ExecuteTime": {
     "start_time": "2023-06-26T12:06:25.892355Z",
     "end_time": "2023-06-26T12:06:29.502203Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "cls = best_model # the best model deducted from cross_validation is already fitted by the cross_validation method,\n",
    "# avoids overfitting\n",
    "\n",
    "# otherwise:\n",
    "# cls = best_cls\n",
    "# cls.fit(X,y)\n",
    "\n",
    "# save with pickle\n",
    "file_name = \"best_model.pkl\"\n",
    "pickle.dump(cls, open(file_name, \"wb\"))\n",
    "### END SOLUTION\n",
    "\n",
    "\n",
    "# load\n",
    "cls = pickle.load(open(file_name, \"rb\"))\n",
    "\n",
    "test_set = pd.read_csv(\"test_set_noclass.csv\")\n",
    "predictions = cls.predict(test_set)\n",
    "\n",
    "# We are going to run the following code\n",
    "if False:\n",
    "    from sklearn.metrics import f1_score, balanced_accuracy_score\n",
    "    final_test_set = pd.read_csv('test_set_noclass.csv')\n",
    "    ground_truth = final_test_set['CLASS']\n",
    "    print(\"Balanced Accuracy: {}\".format(balanced_accuracy_score(predictions, ground_truth)))\n",
    "    print(\"F1 Weighted-Score: {}\".format(f1_score(predictions, ground_truth, average='weighted')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2pB4bTSj4Bvj"
   },
   "source": [
    "Both metrics should aim above 82%! This is going to be tested by us! Make sure your cross validation or your retrained model achieves high balanced accuracy and f1_score (based on 2.1) (more than 88%) as it should achieve at least 82% in our unknown test set!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "osJK4OGy9J9f"
   },
   "source": [
    "Please provide your feedback regarding this project! Did you enjoy it? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "UpFilLbT9Y03",
    "ExecuteTime": {
     "start_time": "2023-06-26T12:02:36.064005Z",
     "end_time": "2023-06-26T12:02:36.122288Z"
    }
   },
   "outputs": [],
   "source": [
    "# YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
